import streamlit as st
import pandas as pd
import re
from utils.db import get_db

st.set_page_config(page_title="–ê–¥–º—ñ–Ω-–ø–∞–Ω–µ–ª—å", page_icon="üõ†")

# --- –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á ---

def normalize_text(text):
    """
    –û—á–∏—â–∞—î —Ç–µ–∫—Å—Ç —ñ –≤–∏–¥–∞–ª—è—î —Å–º—ñ—Ç—Ç—î–≤—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (–ø—Ä–æ—á–µ—Ä–∫–∏, –∫—Ä–∞–ø–∫–∏).
    """
    if pd.isna(text):
        return None
    
    # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –≤ —Ä—è–¥–æ–∫ —ñ –ø—Ä–∏–±–∏—Ä–∞—î–º–æ –ø—Ä–æ–±—ñ–ª–∏ –∑ –∫—Ä–∞—ó–≤
    text = str(text).strip()
    
    # üõë –°–ü–ò–°–û–ö –°–ú–Ü–¢–¢–Ø (Garbage Values)
    # –Ø–∫—â–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∑–±—ñ–≥–∞—î—Ç—å—Å—è –∑ —Ü–∏–º —Å–ø–∏—Å–∫–æ–º, –º–∏ —ó—ó —ñ–≥–Ω–æ—Ä—É—î–º–æ
    garbage_values = [
        "", "-", "‚Äî", "‚Äì", "_",          # –†—ñ–∑–Ω—ñ –≤–∏–¥–∏ —Ç–∏—Ä–µ —ñ –ø—É—Å—Ç—ñ —Ä—è–¥–∫–∏
        ".", "?", "!",                   # –†–æ–∑–¥—ñ–ª–æ–≤—ñ –∑–Ω–∞–∫–∏
        "n/a", "nan", "null", "none",    # –¢–µ—Ö–Ω—ñ—á–Ω—ñ —Å–ª–æ–≤–∞
        "–Ω–µ–º–∞—î", "–Ω–µ –∑–Ω–∞—é", "no", "-"    # –í—ñ–¥–º–æ–≤–∏ –≤—ñ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    ]
    
    if text.lower() in garbage_values:
        return None  # Pandas –≤–∏–¥–∞–ª–∏—Ç—å —Ü–µ –∑–Ω–∞—á–µ–Ω–Ω—è
        
    # –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏ –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ ("Java    Script" -> "Java Script")
    return " ".join(text.split())

def smart_split(text, delimiter=','):
    """
    –†–æ–∑—É–º–Ω–µ —Ä–æ–∑–±–∏—Ç—Ç—è —Ä—è–¥–∫–∞. –Ü–≥–Ω–æ—Ä—É—î –∫–æ–º–∏ –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ –¥—É–∂–æ–∫ (...).
    """
    if not isinstance(text, str): return [text]
    
    pattern = r',\s*(?![^()]*\))'
    if delimiter == ';':
        parts = text.split(';')
    else:
        parts = re.split(pattern, text)
        
    # –ß–∏—Å—Ç–∏–º–æ –∫–æ–∂–Ω—É —á–∞—Å—Ç–∏–Ω—É —ñ –≤–∏–∫–∏–¥–∞—î–º–æ —Å–º—ñ—Ç—Ç—è
    clean_parts = []
    for p in parts:
        cleaned = normalize_text(p) # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —á–∏—Å—Ç–∏–º–æ –∫–æ–∂–Ω—É —á–∞—Å—Ç–∏–Ω—É
        if cleaned:
            clean_parts.append(cleaned)
            
    return clean_parts

def analyze_column(series):
    # 1. –ë–∞–∑–æ–≤–∞ –æ—á–∏—Å—Ç–∫–∞ (—Ç—É—Ç –≤–∏–¥–∞–ª—è—é—Ç—å—Å—è "-" —ñ " ")
    clean_series = series.apply(normalize_text).dropna()
    
    if clean_series.empty: return "text", {}

    total_rows = len(clean_series)
    unique_vals = clean_series.nunique()
    
    # --- –ï–¢–ê–ü 1: –ü–ï–†–ï–í–Ü–†–ö–ê –ù–ê –†–û–ó–î–Ü–õ–¨–ù–ò–ö–ò ---
    cnt_semicolon = clean_series.str.contains(';', regex=False).sum()
    cnt_comma = clean_series.str.contains(',', regex=False).sum()
    
    delimiter = None
    if cnt_semicolon >= 1: delimiter = ';'
    elif cnt_comma >= 1: delimiter = ','
    
    is_multiple = False
    final_expanded = clean_series

    if delimiter:
        expanded_list = []
        for item in clean_series:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ smart_split, —è–∫–∏–π —Ç–µ–∂ —á–∏—Å—Ç–∏—Ç—å —Å–º—ñ—Ç—Ç—è
            expanded_list.extend(smart_split(item, delimiter))
        
        if expanded_list:
            temp_expanded = pd.Series(expanded_list).str.capitalize()
            unique_options_count = temp_expanded.nunique()
            
            if unique_options_count <= 40:
                is_multiple = True
                final_expanded = temp_expanded

    # --- –ï–¢–ê–ü 2: –í–ò–ó–ù–ê–ß–ï–ù–ù–Ø –¢–ò–ü–£ ---
    q_type = "single_choice"
    
    if is_multiple:
        q_type = "multiple_choice"
        counts = final_expanded.value_counts()
    else:
        clean_series = clean_series.str.capitalize()
        counts = clean_series.value_counts()
        
        # –†–µ–π—Ç–∏–Ω–≥
        try:
            first_chars = [str(k).split()[0] for k in counts.keys()]
            if all(c.isdigit() and 0 <= int(c) <= 10 for c in first_chars) and len(counts) <= 12:
                q_type = "rating"
        except: pass

        # –¢–µ–∫—Å—Ç
        if q_type != "rating":
            avg_len = clean_series.astype(str).map(len).mean()
            unique_ratio = unique_vals / total_rows
            
            # –Ø–∫—â–æ —Ä–µ—á–µ–Ω–Ω—è –¥–æ–≤–≥—ñ –ê–ë–û –¥—É–∂–µ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ
            if avg_len > 35 or (unique_vals > 15 and unique_ratio > 0.7):
                q_type = "text"
                return "text", {"answers": clean_series.head(100).tolist()}

    # --- –ï–¢–ê–ü 3: –§–û–†–ú–£–í–ê–ù–ù–Ø –î–ê–ù–ò–• ---
    final_data = {}
    if len(counts) > 15:
        top_15 = counts.head(15)
        other = counts.iloc[15:].sum()
        final_data = top_15.to_dict()
        if other > 0: final_data["–Ü–Ω—à–µ / –†—ñ–¥–∫—ñ—Å–Ω—ñ"] = int(other)
    else:
        final_data = counts.to_dict()
        
    return q_type, final_data


# --- –ì–û–õ–û–í–ù–ò–ô –Ü–ù–¢–ï–†–§–ï–ô–° ---
st.title("üõ† –Ü–º–ø–æ—Ä—Ç —Ç–∞ –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è")

uploaded_file = st.file_uploader("–û–±–µ—Ä—ñ—Ç—å CSV —Ñ–∞–π–ª", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.write("### –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–≥–ª—è–¥")
    st.dataframe(df.head(3))

    with st.form("survey_form"):
        st.subheader("–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
        title = st.text_input("–ù–∞–∑–≤–∞ –æ–ø–∏—Ç—É–≤–∞–Ω–Ω—è", value=uploaded_file.name.replace(".csv", ""))
        org = st.text_input("–û—Ä–≥–∞–Ω—ñ–∑–∞—Ü—ñ—è", "IT Kamianets")
        category = st.selectbox("–ö–∞—Ç–µ–≥–æ—Ä—ñ—è", ["Dev", "QA", "Psychology", "General"])
        
        # –ê–≤—Ç–æ-–≤–∏–±—ñ—Ä –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è
        all_cols = df.columns.tolist()
        stop_words = ["—á–∞—Å", "time", "timestamp", "email", "–ø–æ—à—Ç–∞", "–ø—ñ–±", "name", "—ñ–º'—è", "–ø—Ä—ñ–∑–≤–∏—â–µ", "user"]
        default_drop = [c for c in all_cols if any(sw in c.lower() for sw in stop_words)]
        
        cols_to_drop = st.multiselect("–í–∏–¥–∞–ª–∏—Ç–∏ –∫–æ–Ω—Ñ—ñ–¥–µ–Ω—Ü—ñ–π–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏:", all_cols, default=default_drop)
        
        submit = st.form_submit_button("–û–±—Ä–æ–±–∏—Ç–∏ –¥–∞–Ω—ñ")

    if submit:
        processing_df = df.drop(columns=cols_to_drop)
        questions_list = []
        bar = st.progress(0)
        
        for idx, col in enumerate(processing_df.columns):
            q_type, q_data = analyze_column(processing_df[col])
            
            questions_list.append({
                "text": col,
                "type": q_type,
                "data": q_data
            })
            bar.progress((idx + 1) / len(processing_df.columns))

        new_survey = {
            "id": abs(hash(title + pd.Timestamp.now().strftime("%S"))) % 100000,
            "title": title,
            "organization": org,
            "category": category,
            "participants": len(df),
            "date": pd.Timestamp.now().strftime("%Y-%m-%d"),
            "status": "Active",
            "questions": questions_list
        }
        
        get_db().surveys.insert_one(new_survey)
        st.success("‚úÖ –£—Å–ø—ñ—à–Ω–æ! –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ.")
        
        with st.expander("–î–µ—Ç–∞–ª—ñ –æ–±—Ä–æ–±–∫–∏ (–ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Ç–∏–ø–∏)"):
            for q in questions_list:
                st.markdown(f"**{q['text']}** -> `{q['type']}`")